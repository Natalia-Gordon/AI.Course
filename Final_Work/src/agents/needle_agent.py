#!/usr/bin/env python3
"""
Needle Agent for Financial Documents
Finds specific information or answers precise questions using advanced retrieval
"""

import re
import os
import sys
from typing import List, Dict, Any, Optional
from pathlib import Path

# Add src to path for imports
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from utils.agent_logger import log_needle_agent
from utils.logger import get_logger
from core.config_manager import ConfigManager


class NeedleAgent:
    """Needle Agent for finding specific information in financial documents"""
    
    def __init__(self, config_path: str = None):
        self.logger = get_logger('needle_agent')
        self.config = ConfigManager(config_path) if config_path else None
        self.logger.info("ðŸš€ Needle Agent initialized")
    
    @log_needle_agent
    def run_needle(self, query: str, contexts: List[Dict]) -> str:
        """Find specific information or answer precise questions."""
        
        try:
            self.logger.info(f"ðŸ” Processing needle query: {query[:100]}...")
            
            # Extract key terms from query
            query_terms = self.extract_query_terms(query)
            
            # Score contexts based on relevance
            scored = []
            for c in contexts:
                text = (c.get("text") or "").lower()
                score = self.calculate_relevance_score(query_terms, text, c)
                
                cpy = dict(c)
                cpy["_score"] = score
                scored.append(cpy)
            
            # Sort by relevance score
            best_matches = sorted(scored, key=lambda x: x["_score"], reverse=True)[:3]
            
            if not best_matches or best_matches[0]["_score"] == 0:
                return "No relevant information found for your query."
            
            # Generate answer
            answer_parts = []
            
            for i, match in enumerate(best_matches):
                if match["_score"] > 0:
                    ref = self.get_reference(match)
                    answer_parts.append(f"Match {i+1} ({ref}):")
                    
                    # Extract relevant text snippet
                    snippet = self.extract_relevant_snippet(query_terms, match.get("text", ""))
                    answer_parts.append(f"{snippet}")
                    answer_parts.append("")
            
            result = "\n".join(answer_parts)
            self.logger.info(f"âœ… Needle query completed, found {len(best_matches)} matches")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ Error in needle query: {e}")
            return f"Error processing needle query: {str(e)}"
    
    def run_needle_with_hybrid_retrieval(self, query: str, hybrid_retriever, k: int = 10) -> str:
        """Find specific information using hybrid retrieval (Pinecone + TF-IDF + Reranking)."""
        
        try:
            self.logger.info(f"ðŸ” Running hybrid retrieval for: {query[:100]}...")
            
            # Use hybrid retriever to get relevant chunks
            hits = hybrid_retriever.search(
                query=query,
                k_dense=k,
                k_sparse=k,
                final_k=min(k, 6)  # Limit final results
            )
            
            if not hits:
                return "No relevant information found for your query."
            
            # Extract key terms from query for snippet extraction
            query_terms = self.extract_query_terms(query)
            
            # Generate answer from retrieved hits
            answer_parts = []
            answer_parts.append(f"ðŸ” Found {len(hits)} relevant chunks for: '{query}'")
            answer_parts.append("")
            
            for i, hit in enumerate(hits[:5]):  # Show top 5 results
                ref = self.get_reference(hit)
                score = hit.get('score', 0.0)
                
                # Extract relevant text snippet - try multiple sources
                text = hit.get('text', '')
                if not text:
                    # Try to get text from metadata
                    text = hit.get('metadata', {}).get('text', '')
                if not text:
                    # Try to get text from chunk_summary
                    text = hit.get('chunk_summary', '')
                if not text:
                    # Fallback to any available text field
                    text = str(hit.get('metadata', {}))
                
                snippet = self.extract_relevant_snippet(query_terms, text)
                
                answer_parts.append(f"Match {i+1} (Score: {score:.3f}, {ref}):")
                answer_parts.append(f"{snippet}")
                answer_parts.append("")
            
            result = "\n".join(answer_parts)
            self.logger.info(f"âœ… Hybrid retrieval completed, found {len(hits)} hits")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ Error in hybrid retrieval: {e}")
            return f"Error in hybrid retrieval: {str(e)}"
    
    def extract_query_terms(self, query: str) -> List[str]:
        """Extract key terms from the query with Hebrew-English mapping."""
        # Remove common words and extract meaningful terms
        stop_words = {"what", "is", "the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for", "of", "with", "by"}
        
        terms = re.findall(r'\b\w+\b', query.lower())
        meaningful_terms = [term for term in terms if term not in stop_words and len(term) > 2]
        
        # Add Hebrew equivalents for financial terms
        hebrew_mappings = {
            'revenue': ['×”×›× ×¡×”', '×¨×•×•×—', '×ª×§×‘×•×œ', '×”×›× ×¡×•×ª'],
            'income': ['×”×›× ×¡×”', '×¨×•×•×—', '×ª×§×‘×•×œ', '×”×›× ×¡×•×ª'],
            'profit': ['×¨×•×•×—', '×”×›× ×¡×”', '×¨×•×•×—×™×'],
            'loss': ['×”×¤×¡×“', '×”×¤×¡×“×”', '×”×¤×¡×“×™×'],
            'million': ['×ž×™×œ×™×•×Ÿ', '×ž×™×œ×™×•× ×™×'],
            'thousand': ['××œ×£', '××œ×¤×™×'],
            'quarter': ['×¨×‘×¢×•×Ÿ', '×¨×‘×¢', '×¨×‘×¢×•× ×™×'],
            'q1': ['×¨×‘×¢×•×Ÿ ×¨××©×•×Ÿ', '×¨×‘×¢×•×Ÿ 1', '×¨×‘×¢×•×Ÿ ×¨××©×•×Ÿ'],
            'q2': ['×¨×‘×¢×•×Ÿ ×©× ×™', '×¨×‘×¢×•×Ÿ 2', '×¨×‘×¢×•×Ÿ ×©× ×™'],
            'q3': ['×¨×‘×¢×•×Ÿ ×©×œ×™×©×™', '×¨×‘×¢×•×Ÿ 3', '×¨×‘×¢×•×Ÿ ×©×œ×™×©×™'],
            'q4': ['×¨×‘×¢×•×Ÿ ×¨×‘×™×¢×™', '×¨×‘×¢×•×Ÿ 4', '×¨×‘×¢×•×Ÿ ×¨×‘×™×¢×™'],
            '2025': ['2025', '×ª×©×¤"×”', '2025'],
            '2024': ['2024', '×ª×©×¤"×“', '2024'],
            'customer': ['×œ×§×•×—', '×œ×§×•×—×•×ª', '×ž×‘×•×˜×—', '×ž×‘×•×˜×—×™×'],
            'deposits': ['×¤×™×§×“×•× ×•×ª', '×”×¤×§×“×•×ª', '×¤×§×“×•×Ÿ', '×”×¤×§×“×”'],
            'branch': ['×¡× ×™×£', '×¡× ×™×¤×™×', '×¡× ×™×¤×™'],
            'network': ['×¨×©×ª', '×ª×©×ª×™×ª', '×¨×©×ª×•×ª'],
            'assets': ['× ×›×¡×™×', '×¨×›×•×©', '× ×›×¡'],
            'liabilities': ['×”×ª×—×™×™×‘×•×™×•×ª', '×—×•×‘×•×ª', '×—×•×‘'],
            'net': ['× ×˜×•', '× ×§×™', '×˜×”×•×¨'],
            'company': ['×—×‘×¨×”', '×¢×¡×§', '××¨×’×•×Ÿ'],
            'report': ['×“×•×—', '×“×™×•×•×—', '×“×•×—×•×ª'],
            'financial': ['×¤×™× × ×¡×™', '×›×¡×¤×™', '×›×œ×›×œ×™'],
            'highlights': ['×¢×™×§×¨×™×', '×¢×™×§×¨', '×“×’×©×™×'],
            'executive': ['×ž× ×”×œ', '× ×™×”×•×œ×™', '×”× ×”×œ×”'],
            'summary': ['×¡×™×›×•×', '×ª×§×¦×™×¨', '×¡×™×›×•×ž×™×'],
            'performance': ['×‘×™×¦×•×¢×™×', '×ª×¤×§×•×“', '×”×™×©×’×™×'],
            'indicators': ['×ž×“×“×™×', '×ž×—×•×•× ×™×', '×¡×ž× ×™×']
        }
        
        # Expand terms with Hebrew equivalents
        expanded_terms = []
        for term in meaningful_terms:
            expanded_terms.append(term)
            if term in hebrew_mappings:
                expanded_terms.extend(hebrew_mappings[term])
        
        return expanded_terms
    
    def calculate_relevance_score(self, query_terms: List[str], text: str, context: Dict) -> float:
        """Calculate relevance score for a context."""
        score = 0.0
        
        # Exact term matches
        for term in query_terms:
            if term in text:
                score += 1.0
        
        # Phrase matches (consecutive terms)
        if len(query_terms) > 1:
            for i in range(len(query_terms) - 1):
                phrase = f"{query_terms[i]} {query_terms[i+1]}"
                if phrase in text:
                    score += 2.0
        
        # Boost for financial terms (English and Hebrew)
        financial_terms = [
            "revenue", "profit", "loss", "income", "expense", "asset", "liability", "equity", 
            "million", "quarter", "q1", "q2", "q3", "q4",
            "×”×›× ×¡×”", "×¨×•×•×—", "×”×¤×¡×“", "×ª×§×‘×•×œ", "× ×›×¡×™×", "×”×ª×—×™×™×‘×•×™×•×ª", "×ž×™×œ×™×•×Ÿ", "×¨×‘×¢×•×Ÿ"
        ]
        
        # Boost for any Hebrew terms (since they're likely relevant in Hebrew documents)
        hebrew_terms = [term for term in query_terms if any(c in '××‘×’×“×”×•×–×¡×¢×¤×¦×§×¨×©×ª' for c in term)]
        for term in hebrew_terms:
            score += 0.3  # Boost for Hebrew terms
        
        # Boost for financial terms
        for term in query_terms:
            if term in financial_terms:
                score += 0.5
        
        # Boost for section type relevance
        section_type = context.get("section_type", "").lower()
        if any(term in section_type for term in query_terms):
            score += 1.0
        
        # Boost for page number if query mentions it
        if re.search(r'page\s+\d+', context.get("text", ""), re.IGNORECASE):
            score += 0.3
        
        # Boost for exact number matches (e.g., "15.2 million", "45 locations")
        for term in query_terms:
            if term.isdigit() or term.replace('.', '').isdigit():
                if term in text:
                    score += 1.5  # Higher boost for exact number matches
        
        return score
    
    def extract_relevant_snippet(self, query_terms: List[str], text: str, max_length: int = 400) -> str:
        """Extract the most relevant snippet from the text with Hebrew support."""
        if not text:
            return ""
        
        # Find the best sentence containing query terms
        # Use a more sophisticated sentence splitting that handles decimals and abbreviations
        sentences = re.split(r'(?<=[.!?])\s+(?=[A-Z×-×ª])', text)
        best_sentence = ""
        best_score = 0
        
        for sentence in sentences:
            sentence_lower = sentence.lower()
            # Score based on both English and Hebrew terms
            score = sum(1 for term in query_terms if term.lower() in sentence_lower)
            if score > best_score:
                best_score = score
                best_sentence = sentence.strip()
        
        if best_sentence:
            # Don't truncate if it's a complete sentence
            if len(best_sentence) <= max_length:
                return best_sentence
            else:
                # Only truncate if absolutely necessary, and try to break at word boundary
                words = best_sentence.split()
                truncated = ""
                for word in words:
                    if len(truncated + " " + word) <= max_length - 3:  # Leave room for "..."
                        truncated += (" " + word) if truncated else word
                    else:
                        break
                return truncated + "..." if truncated else best_sentence[:max_length-3] + "..."
        
        # Fallback: return beginning of text with better truncation
        if len(text) <= max_length:
            return text
        else:
            words = text.split()
            truncated = ""
            for word in words:
                if len(truncated + " " + word) <= max_length - 3:
                    truncated += (" " + word) if truncated else word
                else:
                    break
            return truncated + "..." if truncated else text[:max_length-3] + "..."
    
    def get_reference(self, context: Dict) -> str:
        """Generate a reference string for the context."""
        ref_parts = []
        
        if context.get("page_number"):
            ref_parts.append(f"p{context['page_number']}")
        if context.get("section_type"):
            ref_parts.append(context["section_type"])
        if context.get("file_name"):
            ref_parts.append(context["file_name"])
        
        return " | ".join(ref_parts) if ref_parts else "Unknown"


# Legacy function for backward compatibility
def run_needle(query: str, contexts: List[Dict]) -> str:
    """Legacy function for backward compatibility."""
    agent = NeedleAgent()
    return agent.run_needle(query, contexts)


def run_needle_with_hybrid_retrieval(query: str, hybrid_retriever, k: int = 10) -> str:
    """Legacy function for backward compatibility."""
    agent = NeedleAgent()
    return agent.run_needle_with_hybrid_retrieval(query, hybrid_retriever, k)
