from typing import List, Dict
import re

def run_needle(query: str, contexts: List[Dict]) -> str:
    """Find specific information or answer precise questions."""
    
    # Extract key terms from query
    query_terms = extract_query_terms(query)
    
    # Score contexts based on relevance
    scored = []
    for c in contexts:
        text = (c.get("text") or "").lower()
        score = calculate_relevance_score(query_terms, text, c)
        
        cpy = dict(c)
        cpy["_score"] = score
        scored.append(cpy)
    
    # Sort by relevance score
    best_matches = sorted(scored, key=lambda x: x["_score"], reverse=True)[:3]
    
    if not best_matches or best_matches[0]["_score"] == 0:
        return "No relevant information found for your query."
    
    # Generate answer
    answer_parts = []
    
    for i, match in enumerate(best_matches):
        if match["_score"] > 0:
            ref = get_reference(match)
            answer_parts.append(f"Match {i+1} ({ref}):")
            
            # Extract relevant text snippet
            snippet = extract_relevant_snippet(query_terms, match.get("text", ""))
            answer_parts.append(f"{snippet}")
            answer_parts.append("")
    
    return "\n".join(answer_parts)

def run_needle_with_hybrid_retrieval(query: str, hybrid_retriever, k: int = 10) -> str:
    """Find specific information using hybrid retrieval (Pinecone + TF-IDF + Reranking)."""
    
    try:
        # Use hybrid retriever to get relevant chunks
        hits = hybrid_retriever.search(
            query=query,
            k_dense=k,
            k_sparse=k,
            final_k=min(k, 6)  # Limit final results
        )
        
        if not hits:
            return "No relevant information found for your query."
        
        # Extract key terms from query for snippet extraction
        query_terms = extract_query_terms(query)
        
        # Generate answer from retrieved hits
        answer_parts = []
        answer_parts.append(f" Found {len(hits)} relevant chunks for: '{query}'")
        answer_parts.append("")
        
        for i, hit in enumerate(hits[:5]):  # Show top 5 results
            ref = get_reference(hit)
            score = hit.get('score', 0.0)
            
            # Extract relevant text snippet - try multiple sources
            text = hit.get('text', '')
            if not text:
                # Try to get text from metadata
                text = hit.get('metadata', {}).get('text', '')
            if not text:
                # Try to get text from chunk_summary
                text = hit.get('chunk_summary', '')
            if not text:
                # Fallback to any available text field
                text = str(hit.get('metadata', {}))
            
            snippet = extract_relevant_snippet(query_terms, text)
            
            answer_parts.append(f"Match {i+1} (Score: {score:.3f}, {ref}):")
            answer_parts.append(f"{snippet}")
            answer_parts.append("")
        
        return "\n".join(answer_parts)
        
    except Exception as e:
        return f"Error in hybrid retrieval: {str(e)}"

def extract_query_terms(query: str) -> List[str]:
    """Extract key terms from the query with Hebrew-English mapping."""
    # Remove common words and extract meaningful terms
    stop_words = {"what", "is", "the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for", "of", "with", "by"}
    
    terms = re.findall(r'\b\w+\b', query.lower())
    meaningful_terms = [term for term in terms if term not in stop_words and len(term) > 2]
    
    # Add Hebrew equivalents for financial terms
    hebrew_mappings = {
        'revenue': ['住', '专', '转拽', '住转'],
        'income': ['住', '专', '转拽', '住转'],
        'profit': ['专', '住', '专'],
        'loss': ['驻住', '驻住', '驻住'],
        'million': ['', ''],
        'thousand': ['祝', '驻'],
        'quarter': ['专注', '专注', '专注'],
        'q1': ['专注 专砖', '专注 1', '专注 专砖'],
        'q2': ['专注 砖', '专注 2', '专注 砖'],
        'q3': ['专注 砖砖', '专注 3', '专注 砖砖'],
        'q4': ['专注 专注', '专注 4', '专注 专注'],
        '2025': ['2025', '转砖驻"', '2025'],
        '2024': ['2024', '转砖驻"', '2024'],
        'customer': ['拽', '拽转', '', ''],
        'deposits': ['驻拽转', '驻拽转', '驻拽', '驻拽'],
        'branch': ['住祝', '住驻', '住驻'],
        'network': ['专砖转', '转砖转转', '专砖转转'],
        'assets': ['住', '专砖', '住'],
        'liabilities': ['转转', '转', ''],
        'net': ['', '拽', '专'],
        'company': ['专', '注住拽', '专'],
        'report': ['', '', '转'],
        'financial': ['驻住', '住驻', ''],
        'highlights': ['注拽专', '注拽专', '砖'],
        'executive': ['', '', ''],
        'summary': ['住', '转拽爪专', '住'],
        'performance': ['爪注', '转驻拽', '砖'],
        'indicators': ['', '', '住']
    }
    
    # Expand terms with Hebrew equivalents
    expanded_terms = []
    for term in meaningful_terms:
        expanded_terms.append(term)
        if term in hebrew_mappings:
            expanded_terms.extend(hebrew_mappings[term])
    
    return expanded_terms

def calculate_relevance_score(query_terms: List[str], text: str, context: Dict) -> float:
    """Calculate relevance score for a context."""
    score = 0.0
    
    # Exact term matches
    for term in query_terms:
        if term in text:
            score += 1.0
    
    # Phrase matches (consecutive terms)
    if len(query_terms) > 1:
        for i in range(len(query_terms) - 1):
            phrase = f"{query_terms[i]} {query_terms[i+1]}"
            if phrase in text:
                score += 2.0
    
    # Boost for financial terms (English and Hebrew)
    financial_terms = [
        "revenue", "profit", "loss", "income", "expense", "asset", "liability", "equity", 
        "million", "quarter", "q1", "q2", "q3", "q4",
        "住", "专", "驻住", "转拽", "住", "转转", "", "专注"
    ]
    
    # Boost for any Hebrew terms (since they're likely relevant in Hebrew documents)
    hebrew_terms = [term for term in query_terms if any(c in '住注驻爪拽专砖转' for c in term)]
    for term in hebrew_terms:
        score += 0.3  # Boost for Hebrew terms
    
    # Boost for financial terms
    for term in query_terms:
        if term in financial_terms:
            score += 0.5
    
    # Boost for section type relevance
    section_type = context.get("section_type", "").lower()
    if any(term in section_type for term in query_terms):
        score += 1.0
    
    # Boost for page number if query mentions it
    if re.search(r'page\s+\d+', context.get("text", ""), re.IGNORECASE):
        score += 0.3
    
    # Boost for exact number matches (e.g., "15.2 million", "45 locations")
    for term in query_terms:
        if term.isdigit() or term.replace('.', '').isdigit():
            if term in text:
                score += 1.5  # Higher boost for exact number matches
    
    return score

def extract_relevant_snippet(query_terms: List[str], text: str, max_length: int = 400) -> str:
    """Extract the most relevant snippet from the text with Hebrew support."""
    if not text:
        return ""
    
    # Find the best sentence containing query terms
    # Use a more sophisticated sentence splitting that handles decimals and abbreviations
    sentences = re.split(r'(?<=[.!?])\s+(?=[A-Z-转])', text)
    best_sentence = ""
    best_score = 0
    
    for sentence in sentences:
        sentence_lower = sentence.lower()
        # Score based on both English and Hebrew terms
        score = sum(1 for term in query_terms if term.lower() in sentence_lower)
        if score > best_score:
            best_score = score
            best_sentence = sentence.strip()
    
    if best_sentence:
        # Don't truncate if it's a complete sentence
        if len(best_sentence) <= max_length:
            return best_sentence
        else:
            # Only truncate if absolutely necessary, and try to break at word boundary
            words = best_sentence.split()
            truncated = ""
            for word in words:
                if len(truncated + " " + word) <= max_length - 3:  # Leave room for "..."
                    truncated += (" " + word) if truncated else word
                else:
                    break
            return truncated + "..." if truncated else best_sentence[:max_length-3] + "..."
    
    # Fallback: return beginning of text with better truncation
    if len(text) <= max_length:
        return text
    else:
        words = text.split()
        truncated = ""
        for word in words:
            if len(truncated + " " + word) <= max_length - 3:
                truncated += (" " + word) if truncated else word
            else:
                break
        return truncated + "..." if truncated else text[:max_length-3] + "..."

def get_reference(context: Dict) -> str:
    """Generate a reference string for the context."""
    ref_parts = []
    
    if context.get("page_number"):
        ref_parts.append(f"p{context['page_number']}")
    if context.get("section_type"):
        ref_parts.append(context["section_type"])
    if context.get("file_name"):
        ref_parts.append(context["file_name"])
    
    return " | ".join(ref_parts) if ref_parts else "Unknown"
