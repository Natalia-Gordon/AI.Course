project_name: metadata-hybrid-rag

# Document processing paths
documents_dir: data/documents
processed_dir: data/processed

# Embedding configuration
embedding:
  provider: openai
  model: text-embedding-3-small
  dim: 1536

# Pinecone configuration (matching Middle Course pattern)
pinecone:
  index_name: hybrid-rag

# Chunking configuration
chunking:
  max_chunk_tokens: 400
  overlap_tokens: 60
  budget_ratio: 0.05

# Retrieval configuration
retrieval:
  dense_k: 10
  sparse_k: 10
  final_k: 6

# Reranker configuration
reranker:
  model: cross-encoder/ms-marco-MiniLM-L-6-v2

# Filter configuration
filters:
  section_types: [Summary, Table]

# Financial document specific settings
financial:
  extract_metrics: true
  extract_dates: true
  extract_keywords: true
  table_detection: true

# Evaluation configuration
evaluation:
  # RAGAS evaluation settings
  ragas:
    # Target metrics (must be met for PASS status)
    targets:
      context_precision: 0.75
      context_recall: 0.70
      faithfulness: 0.85
      answer_relevancy: 0.80
    
    # Evaluation strategy
    strategy: "langchain_integrated"
    
    # Test set configuration
    test_set:
      min_questions: 5
      max_questions: 20
      include_tables: true
      include_summaries: true
      include_needle: true
    
    # Answer generation settings
    answer_generation:
      max_length: 500
      include_sources: true
      semantic_alignment: true
      context_expansion: true
  
  # Ground truth configuration
  ground_truth:
    # Source for ground truth
    source: "pinecone_chunks"
    
    # Validation settings
    validate_metadata: true
    require_vector_ids: true
    max_contexts_per_question: 3
  
  # Output configuration
  output:
    # Results file
    results_file: "data/eval/evaluation_results.json"
    
    # Detailed results
    detailed_results: true
    include_metrics: true
    include_performance: true
    
    # Logging
    log_evaluation_steps: true
    log_performance_metrics: true

# Logging configuration
logging:
  # Base logging directory
  base_dir: logs
  
  # Log levels for different components
  levels:
    ragas_evaluation: INFO
    main_system: INFO
    table_qa_agent: INFO
    summary_agent: INFO
    needle_agent: INFO
    router_agent: INFO
    data_loader: INFO
    pinecone_index: INFO
    retrieval: INFO
    evaluation_system: INFO
    ground_truth_manager: INFO
    metrics_calculator: INFO
    test_set_generator: INFO
  
  # Log file naming pattern: {component}_{date}.log
  file_pattern: "{component}_{date}.log"
  
  # Date format for log files
  date_format: "%Y-%m-%d"
  
  # Log rotation settings
  rotation:
    max_size_mb: 10
    backup_count: 7
  
  # Log format
  format: "%(asctime)s | %(name)20s | %(message)s"
  
  # Console logging
  console:
    enabled: true
    level: INFO
  
  # File logging
  file:
    enabled: true
    level: INFO
  
  # Evaluation components logging to single file
  evaluation_logging:
    # Use single file for all evaluation components
    unified_file: true
    filename: "ragas_evaluation_{date}.log"
    # All evaluation components will log to this file
    components:
      - ragas_evaluation
      - evaluation_runner
      - ground_truth_manager
      - metrics_calculator
      - test_set_generator
      - eval.ragas_evaluator
      - config_manager
