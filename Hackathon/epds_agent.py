"""
EPDS (Edinburgh Postnatal Depression Scale) Conversational Agent

×¡×•×›×Ÿ ×“×™× ××™ ×©×× ×”×œ ×©×™×—×” ×—×›××”:
- ×™×•×“×¢ ××ª×™ ×œ×©××•×œ ×©××œ×•×ª EPDS
- ××©×ª××© ×‘-NLP ×œ× ×™×ª×•×— ×¨×’×©×™
- ××ª×—×‘×¨ ×œ××•×“×œ XGBoost ×œ×”×¢×¨×›×ª ×¡×™×›×•×Ÿ
- ×©×•××¨ ×ª×•×¦××•×ª ×‘×¦×•×¨×” ××¡×•×“×¨×ª
"""

import os
import uuid
import pandas as pd
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from textblob import TextBlob

# Pydantic import (needed for BaseModel)
try:
    from pydantic import BaseModel, Field
except ImportError:
    # Fallback if pydantic not available
    class BaseModel:
        pass
    Field = None

# LangChain imports - handle multiple versions gracefully
LANGCHAIN_AVAILABLE = False
ChatOpenAI = None
BaseTool = None
PromptTemplate = None

# Try to import core LangChain components
try:
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import PromptTemplate
    try:
        from langchain.tools import BaseTool
    except ImportError:
        try:
            from langchain_core.tools import BaseTool
        except ImportError:
            BaseTool = None
    LANGCHAIN_AVAILABLE = True
except ImportError as e:
    # LangChain not available - BaseTool will be None
    BaseTool = None  # type: ignore
    print(f"âš ï¸ LangChain not available. Install: pip install langchain langchain-openai (Error: {e})")

# Try to import agent-related classes (these may not exist in all versions)
# These are imported on-demand in _initialize_langchain() to handle version differences
initialize_agent = None
AgentType = None
create_react_agent = None
AgentExecutor = None
create_agent = None

from dotenv import load_dotenv
load_dotenv()

# EPDS questions (Hebrew)
EPDS_QUESTIONS = [
    "×‘×©×‘×•×¢ ×”××—×¨×•×Ÿ, ×”×¦×œ×—×ª×™ ×œ×¦×—×•×§ ×•×œ×¨××•×ª ××ª ×”×¦×“ ×”××¦×—×™×§ ×©×œ ×“×‘×¨×™×",
    "×¦×™×¤×™×ª×™ ×‘×”× ××” ×œ×“×‘×¨×™×",
    "×”××©××ª×™ ××ª ×¢×¦××™ ×œ×œ× ×¡×™×‘×”",
    "×”×¨×’×©×ª×™ ×—×¨×“×” ××• ×“××’×” ×œ×œ× ×¡×™×‘×”",
    "×”×¨×’×©×ª×™ ××¤×•×—×“×ª ××• ××‘×•×”×œ×ª",
    "×”×¨×’×©×ª×™ ×©×”×›×•×œ ×§×©×” ×œ×™ ××“×™",
    "×”×™×” ×œ×™ ×§×©×” ×œ×™×©×•×Ÿ ×‘×’×œ×œ ×“××’×•×ª",
    "×”×¨×’×©×ª×™ ×¢×¦×•×‘×” ××• ××•××œ×œ×”",
    "×”×™×™×ª×™ ×›×œ ×›×š ××•××œ×œ×” ×©×‘×›×™×ª×™",
    "×¢×‘×¨×• ×‘×™ ××—×©×‘×•×ª ×œ×¤×’×•×¢ ×‘×¢×¦××™"
]

EPDS_COLUMN_NAMES = [
    "×¦×—×•×§ ×•×”×¦×“ ×”××¦×—×™×§",
    "×¦×™×¤×™×™×” ×‘×”× ××”",
    "×”××©××” ×¢×¦××™×ª",
    "×“××’×” ×•×—×¨×“×”",
    "×¤×—×“ ×•×‘×”×œ×”",
    "×“×‘×¨×™× ×§×©×™× ××“×™",
    "×§×•×©×™ ×œ×™×©×•×Ÿ",
    "×¢×¦×‘ ×•××•××œ×œ×•×ª",
    "×‘×›×™",
    "××—×©×‘×•×ª ×¤×’×™×¢×” ×¢×¦××™×ª"
]

# Expanded list of Hebrew distress keywords and verbal cues
DISTRESS_KEYWORDS = [
    # Direct emotional distress
    "×§×©×”", "×¢×™×™×¤×”", "×‘×•×“×“×”", "×œ×—×•×¦×”", "×œ× ××¦×œ×™×—×”", "×¢×¦×•×‘×”", "××“×•×›××ª", "×™×™××•×©",
    # Additional emotional states
    "×›×•×¢×¡×ª", "××ª×•×¡×›×œ×ª", "×—×¡×¨×ª ×ª×§×•×•×”", "××¤×•×—×“×ª", "×—×¨×“×”", "×¤×—×“", "×‘×”×œ×”", "×“××’×”",
    "×¢×¦×‘× ×™×ª", "×××•×›×–×‘×ª", "××©××”", "××©××”", "××›×–×‘×”", "×ª×¡×›×•×œ", "×›×¢×¡", "×–×¢×",
    # Physical/mental exhaustion
    "×ª×©×•×©×”", "××•×ª×©×ª", "×—×¡×¨×ª ×× ×¨×’×™×”", "×œ× ×™×›×•×œ×”", "×œ× ×™×›×•×œ×” ×™×•×ª×¨", "× ×©×‘×¨×ª",
    "×œ× ××¦×œ×™×—×” ×œ×”×ª××•×“×“", "××•×¦×¤×ª", "××‘×•×œ×‘×œ×ª", "×œ× ××‘×™× ×”", "××‘×•×“×”",
    # Relationship/social distress
    "×‘×•×“×“×”", "××‘×•×“×“×ª", "×œ× ××‘×™× ×™× ××•×ª×™", "××£ ××—×“ ×œ× ××‘×™×Ÿ", "×œ× ×¨×•××” ××•×ª×™",
    "×§×•×©×™ ×¢× ×”×ª×™× ×•×§", "×œ× ××ª×—×‘×¨×ª", "×§×•×©×™ ×œ×”×ª×—×‘×¨", "×œ× ××•×”×‘×ª", "××¤×—×“×ª",
    # Self-harm/suicidal ideation (high priority)
    "×œ× ×¨×•×¦×” ×œ×—×™×•×ª", "×¨×•×¦×” ×œ××•×ª", "×œ× ×›×“××™", "×œ××” ×œ×™", "××™×Ÿ ×˜×¢×", "××•×‘×“×Ÿ ×ª×§×•×•×”",
    "×œ×¤×’×•×¢ ×‘×¢×¦××™", "×œ×”×™×¤×¦×¢", "×œ××•×ª", "×¡×•×£", "×–×” ×”×¡×•×£",
    # Sleep and daily functioning
    "×œ× ×™×©× ×”", "×œ× ××¦×œ×™×—×” ×œ×™×©×•×Ÿ", "× ×“×•×“×™ ×©×™× ×”", "×¢×™×™×¤×” ×›×œ ×”×–××Ÿ",
    "×œ× ×¨×•×¦×” ×œ×§×•×", "×œ× ×¨×•×¦×” ×œ×¢×©×•×ª ×›×œ×•×", "×œ× ××ª×¤×§×“×ª",
    # Coping difficulties
    "×œ× ×™×•×“×¢×ª ××” ×œ×¢×©×•×ª", "×œ× ×™×•×“×¢×ª ××™×š ×œ×”×ª××•×“×“", "××•×‘×“×ª ×¢×¦×•×ª",
    "×—×¡×¨×ª ××•× ×™×", "×—×¡×¨×ª ×©×œ×™×˜×”", "××¨×’×™×©×” ×œ×›×•×“×”", "××™×Ÿ ××•×¦×"
]


class EPDSState(BaseModel):
    """State for EPDS conversation."""
    session_id: str
    patient_name: str
    epds_answers: List[int] = []
    current_question_index: int = 0
    free_text_collected: bool = False
    free_text: str = ""
    conversation_history: List[Dict[str, str]] = []
    needs_epds_question: bool = True
    needs_free_text: bool = False
    assessment_complete: bool = False


class EPDSAnswerInterpreterTool(BaseTool):
    """Tool for interpreting natural language responses to EPDS questions."""
    
    name: str = "interpret_epds_answer"
    description: str = "Interprets a natural language response to an EPDS question and converts it to a score (0-3). The response should be analyzed based on how often or how much the feeling/behavior occurred in the past week."
    
    def _run(self, question: str, user_response: str) -> str:
        """Interpret natural language response to EPDS question."""
        try:
            response_lower = user_response.lower()
            
            # Direct numeric answer
            numbers = re.findall(r'\d+', user_response)
            if numbers:
                score = int(numbers[0])
                if 0 <= score <= 3:
                    return f"SCORE:{score}"
            
            # Hebrew expressions for frequency/intensity
            # 0 = ×‘×›×œ×œ ×œ× / ××¢×•×œ× ×œ×
            if any(word in response_lower for word in ['×‘×›×œ×œ ×œ×', '××¢×•×œ× ×œ×', '××£ ×¤×¢× ×œ×', '××¤×¡', '0']):
                return "SCORE:0"
            
            # 1 = ×œ× ×œ×¢×ª×™× ×§×¨×•×‘×•×ª / ×›××¢×˜ ××£ ×¤×¢×
            if any(word in response_lower for word in ['×œ× ×œ×¢×ª×™× ×§×¨×•×‘×•×ª', '×›××¢×˜ ×œ×', '×‘×“×¨×š ×›×œ×œ ×œ×', '1']):
                return "SCORE:1"
            
            # 2 = ×œ×¤×¢××™× / ××“×™ ×¤×¢×
            if any(word in response_lower for word in ['×œ×¤×¢××™×', '××“×™ ×¤×¢×', '×‘×™× ×•× ×™', '×§×¦×ª', '2']):
                return "SCORE:2"
            
            # 3 = ×œ×¢×ª×™× ×§×¨×•×‘×•×ª ×××•×“ / ×”×¨×‘×” / ×ª××™×“
            if any(word in response_lower for word in ['×œ×¢×ª×™× ×§×¨×•×‘×•×ª ×××•×“', '×”×¨×‘×”', '×ª××™×“', '×›××¢×˜ ×ª××™×“', '3']):
                return "SCORE:3"
            
            # Try sentiment-based interpretation
            blob = TextBlob(user_response)
            sentiment = blob.sentiment.polarity
            
            # If very negative sentiment, likely higher score (more frequent/problematic)
            if sentiment < -0.5:
                return "SCORE:3"
            elif sentiment < -0.2:
                return "SCORE:2"
            elif sentiment < 0:
                return "SCORE:1"
            else:
                return "SCORE:0"
                
        except Exception as e:
            return f"ERROR: {str(e)}"
    
    async def _arun(self, question: str, user_response: str) -> str:
        """Async version."""
        return self._run(question, user_response)


class SentimentAnalysisTool(BaseTool):
    """Tool for analyzing sentiment and distress in text."""
    
    name: str = "analyze_sentiment"
    description: str = "Analyzes text for emotional sentiment and distress keywords. Returns sentiment score (-1 to 1) and detected keywords."
    
    def _run(self, text: str) -> str:
        """Analyze sentiment and detect distress keywords with enhanced sensitivity."""
        try:
            text_lower = text.lower()
            sentiment = TextBlob(text).sentiment.polarity
            
            # Enhanced keyword detection (check both full words and substrings)
            keywords_found = []
            for keyword in DISTRESS_KEYWORDS:
                if keyword.lower() in text_lower:
                    keywords_found.append(keyword)
            
            # Check for high-priority distress indicators (suicidal ideation, self-harm)
            high_priority_keywords = ["×œ× ×¨×•×¦×” ×œ×—×™×•×ª", "×¨×•×¦×” ×œ××•×ª", "×œ×¤×’×•×¢ ×‘×¢×¦××™", "×œ×”×™×¤×¦×¢", 
                                     "×œ× ×›×“××™", "××™×Ÿ ×˜×¢×", "××•×‘×“×Ÿ ×ª×§×•×•×”", "×–×” ×”×¡×•×£"]
            has_high_priority = any(kw in text_lower for kw in high_priority_keywords)
            
            # Enhanced distress level calculation
            # Factor in sentiment, keyword count, and priority indicators
            keyword_count = len(keywords_found)
            if has_high_priority:
                distress_level = "×’×‘×•×” ×××•×“"
                urgency = "×“×—×•×£"
            elif sentiment < -0.4 or keyword_count >= 3:
                distress_level = "×’×‘×•×”"
                urgency = "×’×‘×•×”"
            elif sentiment < -0.2 or keyword_count >= 2:
                distress_level = "×‘×™× ×•× ×™-×’×‘×•×”"
                urgency = "×‘×™× ×•× ×™"
            elif sentiment < 0 or keyword_count >= 1:
                distress_level = "×‘×™× ×•× ×™"
                urgency = "× ××•×š-×‘×™× ×•× ×™"
            else:
                distress_level = "× ××•×š"
                urgency = "× ××•×š"
            
            result = {
                "sentiment_score": round(sentiment, 2),
                "distress_level": distress_level,
                "urgency": urgency,
                "keywords": keywords_found,
                "high_priority": has_high_priority,
                "keyword_count": keyword_count
            }
            
            return f"× ×™×ª×•×— ×¨×’×©×™: ×¨××ª ××¦×•×§×” {distress_level} (×“×—×™×¤×•×ª: {urgency}), ×¦×™×•×Ÿ ×¨×’×©×™: {result['sentiment_score']}, ××™×œ×•×ª ××¤×ª×—: {', '.join(result['keywords'][:5]) if result['keywords'] else '××™×Ÿ'}"
        except Exception as e:
            return f"×©×’×™××” ×‘× ×™×ª×•×— ×¨×’×©×™: {str(e)}"
    
    async def _arun(self, text: str) -> str:
        """Async version."""
        return self._run(text)


class PPDPredictionTool(BaseTool):
    """Tool for predicting PPD risk using XGBoost model."""
    
    name: str = "predict_ppd_risk"
    description: str = "Predicts PPD risk using the trained XGBoost model. Requires symptom data. Returns risk score and level."
    
    ppd_agent: Optional[Any] = None
    
    def __init__(self, ppd_agent=None, **kwargs):
        super().__init__(**kwargs)
        self.ppd_agent = ppd_agent
    
    def _run(self, age: str = "25-30", feeling_sad: str = "No", irritable: str = "No",
             trouble_sleeping: str = "No", concentration: str = "No", appetite: str = "No",
             feeling_anxious: str = "No", guilt: str = "No", bonding: str = "No",
             suicide_attempt: str = "No") -> str:
        """Predict PPD risk."""
        if self.ppd_agent is None:
            return "××•×“×œ PPD ×œ× ×–××™×Ÿ ×›×¨×’×¢"
        
        try:
            result = self.ppd_agent.predict(
                age=age,
                feeling_sad=feeling_sad,
                irritable=irritable,
                trouble_sleeping=trouble_sleeping,
                concentration=concentration,
                appetite=appetite,
                feeling_anxious=feeling_anxious,
                guilt=guilt,
                bonding=bonding,
                suicide_attempt=suicide_attempt
            )
            
            return f"×”×¢×¨×›×ª ×¡×™×›×•×Ÿ PPD: {result['risk_level']} ({result['risk_percentage']}%). {result['explanation'][:200]}"
        except Exception as e:
            return f"×©×’×™××” ×‘×”×¢×¨×›×ª ×¡×™×›×•×Ÿ: {str(e)}"
    
    async def _arun(self, **kwargs) -> str:
        """Async version."""
        return self._run(**kwargs)


def save_epds_assessment(state: EPDSState, sentiment_score: float, keywords: List[str]) -> Tuple[int, int]:
    """Save EPDS assessment to CSV file."""
    data_dir = Path(__file__).parent / "data"
    data_dir.mkdir(exist_ok=True)
    
    csv_path = data_dir / "EPDS_answers.csv"
    
    # Get next ID
    if csv_path.exists():
        try:
            existing_df = pd.read_csv(csv_path, encoding='utf-8-sig')
            if 'ID' in existing_df.columns:
                next_id = int(existing_df['ID'].max()) + 1
            else:
                next_id = len(existing_df) + 1
        except Exception:
            next_id = 1
    else:
        next_id = 1
    
    # Create timestamp
    timestamp = datetime.now().strftime("%m/%d/%Y %H:%M")
    
    # Calculate total score
    total_score = sum(state.epds_answers)
    
    # Ensure we have exactly 10 answers
    answers = state.epds_answers.copy()
    while len(answers) < 10:
        answers.append(0)
    
    # Create row data
    row_data = {
        "ID": [next_id],
        "Timestamp": [timestamp],
        "Name": [state.patient_name if state.patient_name else f"Patient_{next_id}"],
        "Total Scores": [total_score]
    }
    
    # Add individual question scores
    for i, col_name in enumerate(EPDS_COLUMN_NAMES):
        row_data[col_name] = [answers[i] if i < len(answers) else 0]
    
    df = pd.DataFrame(row_data)
    
    # Append to existing file or create new one
    if csv_path.exists():
        df.to_csv(csv_path, mode='a', header=False, index=False, encoding='utf-8-sig')
    else:
        df.to_csv(csv_path, mode='w', header=True, index=False, encoding='utf-8-sig')
    
    print(f"âœ… Saved EPDS assessment: ID={next_id}, Score={total_score}, Name={state.patient_name}")
    return next_id, total_score


def extract_answer_score(text: str) -> Optional[int]:
    """Extract EPDS answer score (0-3) from text."""
    # Try numeric extraction
    numbers = re.findall(r'\d+', text)
    if numbers:
        score = int(numbers[0])
        if 0 <= score <= 3:
            return score
    
    # Check for Hebrew responses
    text_lower = text.lower()
    if any(word in text_lower for word in ['×‘×›×œ×œ ×œ×', '×œ×', '0']):
        return 0
    elif any(word in text_lower for word in ['×œ×¢×ª×™×', '1', '×§×¦×ª']):
        return 1
    elif any(word in text_lower for word in ['×œ×¤×¢××™×', '2', '×‘×™× ×•× ×™']):
        return 2
    elif any(word in text_lower for word in ['×§×¨×•×‘×•×ª', '3', '×”×¨×‘×”', '×ª××™×“']):
        return 3
    
    return None


class EPDSAgent:
    """
    ×¡×•×›×Ÿ EPDS ×“×™× ××™ ×¢× LangChain
    
    ×× ×”×œ ×©×™×—×” ×—×›××” ×©×™×•×“×¢×ª:
    - ××ª×™ ×œ×©××•×œ ×©××œ×•×ª EPDS
    - ××ª×™ ×œ××¡×•×£ ×˜×§×¡×˜ ×—×•×¤×©×™
    - ××™×š ×œ× ×ª×— ×¨×’×©×•×ª
    - ××™×š ×œ×”×ª×—×‘×¨ ×œ××•×“×œ XGBoost
    """
    
    def __init__(self, ppd_agent=None):
        """Initialize EPDS Agent."""
        self.ppd_agent = ppd_agent
        self.llm = None
        self.langchain_agent = None
        self.state: Optional[EPDSState] = None
        
        if LANGCHAIN_AVAILABLE:
            self._initialize_langchain()
    
    def _initialize_langchain(self):
        """Initialize LangChain components."""
        try:
            openai_api_key = os.getenv("OPENAI_API_KEY")
            if not openai_api_key:
                print("âš ï¸ OPENAI_API_KEY not found. EPDS agent will work in basic mode.")
                return
            
            # Initialize LLM
            self.llm = ChatOpenAI(
                temperature=0.7,
                model="gpt-4o-mini",
                openai_api_key=openai_api_key
            )
            
            # Create tools
            tools = [
                SentimentAnalysisTool(),
                EPDSAnswerInterpreterTool(),
            ]
            
            # Add PPD prediction tool if agent is available
            if self.ppd_agent is not None:
                tools.append(PPDPredictionTool(ppd_agent=self.ppd_agent))
            
            # Create prompt template for EPDS conversation
            prompt = PromptTemplate.from_template("""××ª×” ×¡×•×›×Ÿ ×¨×¤×•××™ ××§×¦×•×¢×™ ×©×× ×”×œ ×”×¢×¨×›×” ×©×œ ×“×™×›××•×Ÿ ×œ××—×¨ ×œ×™×“×” (EPDS).

×”××˜×¨×”: ×œ× ×”×œ ×©×™×—×” ×˜×‘×¢×™×ª ×•×œ××¡×•×£ ××™×“×¢ ×¢×œ ××¦×‘×” ×”×¨×’×©×™ ×©×œ ×”××˜×•×¤×œ×ª.

×›×œ×™× ×–××™× ×™×:
{tools}

×”×•×¨××•×ª:
1. ×”×ª×—×œ ×‘×‘×¨×›×” ×—××” ×•×”×¡×‘×¨ ×¢×œ ×”×ª×”×œ×™×š
2. ×©××œ ×©××œ×•×ª EPDS ××—×ª ××—×¨×™ ×”×©× ×™×™×” (0-3), ××‘×œ ××¤×©×¨ ×’× ×©×™×—×” ×—×•×¤×©×™×ª
3. ×× ×”××˜×•×¤×œ×ª ××©×ª×¤×ª ×¨×’×©×•×ª, ×”×©×ª××© ×‘×›×œ×™ analyze_sentiment ×œ× ×™×ª×•×—
4. ××¡×•×£ ×˜×§×¡×˜ ×—×•×¤×©×™ ×¢×œ ×¨×’×©×•×ª ×‘×¡×•×£
5. ×œ××—×¨ ×”×©×œ××ª EPDS, ×”×¦×¢ ×—×™×‘×•×¨ ×œ××•×“×œ XGBoost ×œ×”×¢×¨×›×ª ×¡×™×›×•×Ÿ

×©××œ×•×ª EPDS:
{epds_questions}

××¦×‘ × ×•×›×—×™:
- ×©××œ×•×ª ×©× ×¢× ×•: {answered_questions}
- ×©××œ×” × ×•×›×—×™×ª: {current_question_index}
- ×˜×§×¡×˜ ×—×•×¤×©×™ × ××¡×£: {free_text_collected}

×ª×’×•×‘×” ×©×œ ×”××˜×•×¤×œ×ª: {user_message}

×ª×’×•×‘×”:""")
            
            # Try to create agent (various API versions) - import on-demand
            agent_created = False
            
            # Try LangChain 1.x API (create_agent)
            try:
                from langchain.agents import create_agent
                self.langchain_agent = create_agent(
                    model=self.llm,
                    tools=tools,
                    system_prompt="××ª×” ×¡×•×›×Ÿ EPDS ××§×¦×•×¢×™ ×©×× ×”×œ ×©×™×—×•×ª ×¨×’×™×©×•×ª ×¢× × ×©×™× ×œ××—×¨ ×œ×™×“×”."
                )
                agent_created = True
            except (ImportError, AttributeError, Exception) as e:
                # Try create_react_agent (0.3.x) if not created yet
                try:
                    from langchain.agents import create_react_agent, AgentExecutor
                    prompt_template = PromptTemplate.from_template(prompt.template)
                    agent = create_react_agent(self.llm, tools, prompt_template)
                    self.langchain_agent = AgentExecutor(agent=agent, tools=tools, verbose=False)
                    agent_created = True
                except (ImportError, AttributeError, Exception) as e2:
                    # Fallback to initialize_agent (old API) if not created yet
                    try:
                        from langchain.agents import initialize_agent, AgentType
                        self.langchain_agent = initialize_agent(
                            tools=tools,
                            llm=self.llm,
                            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                            verbose=False
                        )
                        agent_created = True
                    except (ImportError, AttributeError, Exception) as e3:
                        # If all fail, we'll continue without LangChain agent
                        # The EPDS agent can still work in basic mode
                        agent_created = False
            
            if not agent_created:
                # Don't raise an error - allow the agent to work without LangChain
                print("âš ï¸ Could not initialize LangChain agent. EPDS agent will work in basic mode without advanced NLP.")
                self.langchain_agent = None
                return
            
            print("âœ… EPDS LangChain agent initialized successfully")
            
        except Exception as e:
            print(f"âš ï¸ Could not initialize LangChain agent: {e}")
            self.langchain_agent = None
    
    def start_conversation(self, patient_name: str = "") -> str:
        """Start a new EPDS conversation with a sensitive, non-intrusive greeting."""
        name_part = f" {patient_name}" if patient_name else ""
        self.state = EPDSState(
            session_id=str(uuid.uuid4()),
            patient_name=patient_name if patient_name else f"Patient_{uuid.uuid4().hex[:8]}",
            needs_epds_question=True,
            needs_free_text=False,
            assessment_complete=False
        )
        
        # More sensitive and non-intrusive greeting - emphasizing natural language
        greeting = f"×©×œ×•×{name_part}! ğŸ’™\n\n"
        greeting += f"×× ×™ ×›××Ÿ ×›×“×™ ×œ×”×§×©×™×‘ ×•×œ×¢×–×•×¨ ×œ×š ×œ×”×‘×™×Ÿ ×˜×•×‘ ×™×•×ª×¨ ××™×š ××ª ××¨×’×™×©×” ×‘×ª×§×•×¤×” ×”×–××ª.\n\n"
        greeting += f"×× ×™ ××©××œ ××•×ª×š ×›××” ×©××œ×•×ª ×§×¦×¨×•×ª ×¢×œ ×”×©×‘×•×¢ ×”××—×¨×•×Ÿ. "
        greeting += f"××™×Ÿ ×ª×©×•×‘×•×ª × ×›×•× ×•×ª ××• ×©×’×•×™×•×ª - ×—×©×•×‘ ×œ×™ ×œ×©××•×¢ ×‘×“×™×•×§ ××™×š ××ª ××¨×’×™×©×”.\n\n"
        greeting += f"ğŸ’¬ ××ª ××•×–×× ×ª ×œ×¢× ×•×ª ×‘×“×¨×š ×”×˜×‘×¢×™×ª ×©×œ×š - ×‘××™×œ×™× ×©×œ×š, ×›××•×•×ª × ×¤×©×š. "
        greeting += f"×× ×™ ××‘×™× ×” ×¢×‘×¨×™×ª ×•××§×©×™×‘ ×œ×š ×‘×§×©×‘. ×× ×ª×¨×¦×™, ××ª ×™×›×•×œ×” ×’× ×œ×¢× ×•×ª ×¢× ××¡×¤×¨ (0-3):\n"
        greeting += f"â€¢ 0 = ×‘×›×œ×œ ×œ×\n"
        greeting += f"â€¢ 1 = ×œ× ×œ×¢×ª×™× ×§×¨×•×‘×•×ª\n"
        greeting += f"â€¢ 2 = ×œ×¤×¢××™×\n"
        greeting += f"â€¢ 3 = ×œ×¢×ª×™× ×§×¨×•×‘×•×ª ×××•×“\n\n"
        greeting += f"ğŸ’™ ×× ×ª×¨×¦×™ ×œ×©×ª×£ ×¨×’×©×•×ª ××• ××—×©×‘×•×ª × ×•×¡×¤×•×ª, ××ª ××•×–×× ×ª ×œ×¢×©×•×ª ×–××ª ×‘×›×œ ×©×œ×‘. "
        greeting += f"×× ×™ ×›××Ÿ ×œ×”×§×©×™×‘ ×•×œ×ª××•×š.\n\n"
        greeting += f"×‘×•××™ × ×ª×—×™×œ:\n\n×©××œ×” 1:\n{EPDS_QUESTIONS[0]}"
        
        self.state.conversation_history.append({
            "role": "assistant",
            "content": greeting
        })
        
        return greeting
    
    def process_message(self, user_message: str) -> str:
        """Process user message and return agent response."""
        if self.state is None:
            return "×× × ×”×ª×—×™×œ×™ ×©×™×—×” ×§×•×“×"
        
        # Add user message to history
        self.state.conversation_history.append({
            "role": "user",
            "content": user_message
        })
        
        # Check if we're in EPDS question phase
        if self.state.current_question_index < len(EPDS_QUESTIONS):
            # Get current question
            current_question = EPDS_QUESTIONS[self.state.current_question_index]
            
            # Always check for emotional distress first - even if they gave a numeric answer
            sentiment_tool = SentimentAnalysisTool()
            sentiment_result = sentiment_tool._run(user_message)
            
            # Check for high-priority distress indicators (suicidal ideation, self-harm)
            high_priority_keywords = ["×œ× ×¨×•×¦×” ×œ×—×™×•×ª", "×¨×•×¦×” ×œ××•×ª", "×œ×¤×’×•×¢ ×‘×¢×¦××™", "×œ×”×™×¤×¦×¢", 
                                     "×œ× ×›×“××™", "××™×Ÿ ×˜×¢×", "××•×‘×“×Ÿ ×ª×§×•×•×”", "×–×” ×”×¡×•×£"]
            text_lower = user_message.lower()
            has_high_priority_distress = any(kw in text_lower for kw in high_priority_keywords)
            
            # If high priority distress detected, respond with immediate support
            if has_high_priority_distress:
                response = "ğŸ’™ ×× ×™ ××‘×™× ×” ×©××ª ×—×•×•×” ×§×•×©×™ ×’×“×•×œ. ×—×©×•×‘ ×œ×™ ×©×ª×“×¢×™ ×©××ª ×œ× ×œ×‘×“.\n\n"
                response += "×× ××ª ×—×•×•×” ××—×©×‘×•×ª ×§×©×•×ª ××• ××—×©×‘×•×ª ×¢×œ ×¤×’×™×¢×” ×‘×¢×¦××š, ×× ×™ ×××œ×™×¦×” ×‘×—×•× ×œ×¤× ×•×ª ××™×“ ×œ×¢×–×¨×” ××§×¦×•×¢×™×ª:\n"
                response += "â€¢ ×¢×¨×´×Ÿ (×—×™×¨×•× × ×¤×©×™): 1201\n"
                response += "â€¢ × ×˜×´×œ: 1-800-363-363\n"
                response += "â€¢ ××• ×¤× ×™ ×œ×—×“×¨ ××™×•×Ÿ ×§×¨×•×‘\n\n"
                response += "×× ×™ ×›××Ÿ ×œ×”×§×©×™×‘. ×¨×•×¦×” ×œ×©×ª×£ ×¢×•×“?\n\n"
                response += f"×‘×•××™ × ××©×™×š ×¢× ×”×©××œ×”:\n{EPDS_QUESTIONS[self.state.current_question_index]}\n"
                response += "(×ª×•×›×œ×™ ×œ×¢× ×•×ª 0-3 ××• ×œ×©×ª×£ ×¨×’×©×•×ª × ×•×¡×¤×™×)"
            
            # Try to extract numeric answer
            answer = extract_answer_score(user_message)
            
            if answer is not None:
                # Valid answer - save and move to next question
                self.state.epds_answers.append(answer)
                self.state.current_question_index += 1
                
                # Check for emotional content even in numeric answers
                has_distress_keywords = any(kw in user_message for kw in DISTRESS_KEYWORDS)
                
                if self.state.current_question_index < len(EPDS_QUESTIONS):
                    # More questions to ask
                    next_q = EPDS_QUESTIONS[self.state.current_question_index]
                    if has_distress_keywords and not has_high_priority_distress:
                        # Acknowledge the emotional sharing before continuing
                        response = f"×ª×•×“×” ×¢×œ ×”×©×™×ª×•×£ ×”×›× ×” ğŸ’™\n\n×©××œ×” {self.state.current_question_index + 1}:\n{next_q}"
                    else:
                        response = f"×ª×•×“×”! ×©××œ×” {self.state.current_question_index + 1}:\n{next_q}"
                else:
                    # All questions answered - ask for free text in a sensitive way
                    self.state.needs_free_text = True
                    response = "×ª×•×“×” ×¨×‘×” ×¢×œ ×”×©×™×ª×•×£ ×”×›× ×” ×•×”×××•×Ÿ ğŸ’™\n\n"
                    response += "×× ×ª×¨×¦×™, ×× ×™ ×›××Ÿ ×œ×”×§×©×™×‘ - ×¨×•×¦×” ×œ×©×ª×£ ×‘××©×¤×˜ ××• ×©× ×™×™× ××™×š ××ª ××¨×’×™×©×” ×¨×’×©×™×ª ×‘×ª×§×•×¤×” ×”×–××ª? "
                    response += "×–×” ×™×¢×–×•×¨ ×œ×™ ×œ×”×‘×™×Ÿ ×˜×•×‘ ×™×•×ª×¨ ××ª ×”××¦×‘ ×©×œ×š, ××‘×œ ×–×” ×œ×’××¨×™ ××•×¤×¦×™×•× ×œ×™."
            else:
                # No clear answer extracted - use LLM to understand and respond naturally
                has_distress_keywords = any(kw in user_message for kw in DISTRESS_KEYWORDS)
                
                if self.llm is not None and not has_high_priority_distress:
                    # Use LLM to generate a natural, empathetic response
                    try:
                        llm_context = f"""××ª×” ×¡×•×›×Ÿ ×¨×¤×•××™ ×××¤×ª×™ ×©×× ×”×œ ×©×™×—×” ×¢× ××™×©×” ×œ××—×¨ ×œ×™×“×”.

×”×©××œ×” ×”× ×•×›×—×™×ª: {current_question}

×”×ª×©×•×‘×” ×©×œ ×”××˜×•×¤×œ×ª: {user_message}

×”×ª×©×•×‘×” ×œ× ×‘×¨×•×¨×” ×›×¦×™×•×Ÿ ××¡×¤×¨×™ (0-3). ×ª×¤×§×™×“×š:
1. ×œ×”×‘×™×Ÿ ××ª ×”×ª×©×•×‘×” ×‘××™×œ×™× ×”×˜×‘×¢×™×•×ª ×©×œ×”
2. ×œ××©×¨ ×©××ª ××‘×™×Ÿ/×” (×××¤×ª×™×”)
3. ×œ× ×¡×•×ª ×œ×¤×¨×© ××ª ×”×ª×©×•×‘×” ×œ×¦×™×•×Ÿ 0-3 ×× ××¤×©×¨
4. ×× ×œ× ××¤×©×¨, ×œ×”×–××™×Ÿ ××•×ª×” ×œ×¤×¨×˜ ×§×¦×ª ×™×•×ª×¨

×—×–×•×¨ ×¢× ×ª×’×•×‘×” ×§×¦×¨×”, ×××¤×ª×™×ª ×•×˜×‘×¢×™×ª ×‘×¢×‘×¨×™×ª. ×× ×”×¦×œ×—×ª ×œ×¤×¨×© ×œ×¦×™×•×Ÿ, ×¦×™×™×Ÿ ××•×ª×• ×‘×¡×•×£ ×‘×¦×•×¨×” ×¢×“×™× ×”."""
                        
                        llm_response = self.llm.invoke(llm_context).content.strip()
                        response = llm_response
                        
                        # Try to extract any score the LLM might have inferred
                        extracted_score = extract_answer_score(llm_response)
                        if extracted_score is not None:
                            answer = extracted_score
                            self.state.epds_answers.append(answer)
                            self.state.current_question_index += 1
                            if self.state.current_question_index < len(EPDS_QUESTIONS):
                                response += f"\n\n×©××œ×” {self.state.current_question_index + 1}:\n{EPDS_QUESTIONS[self.state.current_question_index]}"
                            else:
                                self.state.needs_free_text = True
                                response += "\n\n×ª×•×“×” ×¨×‘×” ×¢×œ ×”×©×™×ª×•×£ ×”×›× ×” ğŸ’™\n"
                                response += "×× ×ª×¨×¦×™, ×× ×™ ×›××Ÿ ×œ×”×§×©×™×‘ - ×¨×•×¦×” ×œ×©×ª×£ ×‘××©×¤×˜ ××• ×©× ×™×™× ××™×š ××ª ××¨×’×™×©×” ×¨×’×©×™×ª ×‘×ª×§×•×¤×” ×”×–××ª?"
                        else:
                            # Add the current question again for context
                            response += f"\n\n×”×©××œ×” ×”×™×:\n{current_question}"
                    except Exception as e:
                        # Fallback if LLM fails
                        if has_distress_keywords and not has_high_priority_distress:
                            response = f"×× ×™ ××‘×™× ×” ×©××ª ××©×ª×¤×ª ×¨×’×©×•×ª, ×ª×•×“×” ×¢×œ ×”×××•×Ÿ ğŸ’™\n\n"
                            response += f"×‘×•××™ × ××©×™×š ×¢× ×”×©××œ×”:\n{current_question}\n\n"
                            response += f"×ª×•×›×œ×™ ×œ×¢× ×•×ª ×‘××™×œ×™× ×©×œ×š ××• ×¢× ××¡×¤×¨ (0-3)."
                        else:
                            response = f"×× ×™ ×›××Ÿ ×œ×”×§×©×™×‘ ğŸ’™\n\n"
                            response += f"×‘×•××™ × ××©×™×š ×¢× ×”×©××œ×”:\n{current_question}\n\n"
                            response += f"×ª×•×›×œ×™ ×œ×¢× ×•×ª ×‘××™×œ×™× ×©×œ×š ××• ×¢× ××¡×¤×¨ (0 = ×‘×›×œ×œ ×œ×, 1 = ×œ× ×œ×¢×ª×™× ×§×¨×•×‘×•×ª, 2 = ×œ×¤×¢××™×, 3 = ×œ×¢×ª×™× ×§×¨×•×‘×•×ª ×××•×“)"
                else:
                    # No LLM available - use rule-based response
                    if has_distress_keywords and not has_high_priority_distress:
                        response = f"×× ×™ ××‘×™× ×” ×©××ª ××©×ª×¤×ª ×¨×’×©×•×ª, ×ª×•×“×” ×¢×œ ×”×××•×Ÿ ğŸ’™\n\n"
                        response += f"×‘×•××™ × ××©×™×š ×¢× ×”×©××œ×”:\n{current_question}\n\n"
                        response += f"×ª×•×›×œ×™ ×œ×¢× ×•×ª ×‘××™×œ×™× ×©×œ×š ××• ×¢× ××¡×¤×¨ (0-3)."
                    else:
                        response = f"×× ×™ ×›××Ÿ ×œ×”×§×©×™×‘ ğŸ’™\n\n"
                        response += f"×‘×•××™ × ××©×™×š ×¢× ×”×©××œ×”:\n{current_question}\n\n"
                        response += f"×ª×•×›×œ×™ ×œ×¢× ×•×ª ×‘××™×œ×™× ×©×œ×š ××• ×¢× ××¡×¤×¨ (0 = ×‘×›×œ×œ ×œ×, 1 = ×œ× ×œ×¢×ª×™× ×§×¨×•×‘×•×ª, 2 = ×œ×¤×¢××™×, 3 = ×œ×¢×ª×™× ×§×¨×•×‘×•×ª ×××•×“)"
        
        elif self.state.needs_free_text and not self.state.free_text_collected:
            # Collecting free text - enhanced emotional sensitivity
            self.state.free_text = user_message
            self.state.free_text_collected = True
            
            # Analyze sentiment with enhanced detection
            sentiment, keywords = self._analyze_sentiment(user_message)
            
            # Check for high-priority distress
            text_lower = user_message.lower()
            high_priority_keywords = ["×œ× ×¨×•×¦×” ×œ×—×™×•×ª", "×¨×•×¦×” ×œ××•×ª", "×œ×¤×’×•×¢ ×‘×¢×¦××™", "×œ×”×™×¤×¦×¢", 
                                     "×œ× ×›×“××™", "××™×Ÿ ×˜×¢×", "××•×‘×“×Ÿ ×ª×§×•×•×”", "×–×” ×”×¡×•×£"]
            has_high_priority = any(kw in text_lower for kw in high_priority_keywords)
            
            # Save assessment
            record_id, total_score = save_epds_assessment(
                self.state,
                sentiment,
                keywords
            )
            
            # Determine risk level
            risk_assessment = self._assess_risk(total_score, sentiment, keywords)
            
            # Generate sensitive, supportive response
            response = f"×ª×•×“×” ×¨×‘×” ×¢×œ ×”×©×™×ª×•×£ ×”×›× ×” ×•×”×××•×Ÿ ğŸ’™\n\n"
            
            # If high priority distress detected, add immediate support message
            if has_high_priority:
                response += "âš ï¸ ×× ×™ ×¨×•×¦×” ×œ×”×“×’×™×©: ×× ××ª ×—×•×•×” ××—×©×‘×•×ª ×§×©×•×ª ××• ××—×©×‘×•×ª ×¢×œ ×¤×’×™×¢×” ×‘×¢×¦××š, "
                response += "×× ×™ ×××œ×™×¦×” ×‘×—×•× ×œ×¤× ×•×ª ××™×“ ×œ×¢×–×¨×” ××§×¦×•×¢×™×ª:\n"
                response += "â€¢ ×¢×¨×´×Ÿ (×—×™×¨×•× × ×¤×©×™): 1201\n"
                response += "â€¢ × ×˜×´×œ: 1-800-363-363\n"
                response += "â€¢ ××• ×¤× ×™ ×œ×—×“×¨ ××™×•×Ÿ ×§×¨×•×‘\n\n"
            
            response += f"ğŸ“Š ×ª×•×¦××•×ª ×”×”×¢×¨×›×”:\n"
            response += f"×¦×™×•×Ÿ EPDS: {total_score}/30\n"
            response += f"×¨××ª ×¡×™×›×•×Ÿ: {risk_assessment['risk_level']}\n\n"
            response += f"ğŸ’™ {risk_assessment['recommendation']}\n\n"
            
            # Add supportive message based on risk level
            if total_score >= 13:
                response += "×× ×™ ×¨×•××” ×©××ª ×—×•×•×” ×§×•×©×™ ××©××¢×•×ª×™. ×–×” ×œ×’××¨×™ × ×•×¨××œ×™ ×•× ×¤×•×¥, ×•××ª ×œ× ×œ×‘×“. "
                response += "×”×¨×‘×” ××™××”×•×ª ×—×•×•×ª ×ª×—×•×©×•×ª ×“×•××•×ª ×œ××—×¨ ×œ×™×“×”. ××•××œ×¥ ×××•×“ ×œ×©×§×•×œ ×¤× ×™×” ×œ×™×™×¢×•×¥ ××§×¦×•×¢×™ ×©×™×›×•×œ ×œ×¢×–×•×¨. "
                response += "×™×© ×ª××™×›×” ×–××™× ×”, ×•××ª ×¨××•×™×” ×œ×§×‘×œ ××•×ª×”. ğŸ’™\n\n"
            elif total_score >= 10:
                response += "×× ×™ ×¨×•××” ×©×™×© ×ª×—×•×©×•×ª ×©×œ ×§×•×©×™. ×—×©×•×‘ ×œ×¢×§×•×‘ ××—×¨×™ ×”××¦×‘ ×•×œ×”×™×•×ª ×§×©×•×‘×” ×œ×¢×¦××š. "
                response += "×× ×”×ª×—×•×©×•×ª × ××©×›×•×ª ××• ××ª×—×–×§×•×ª, ×–×” ×‘×¡×“×¨ ×œ×‘×§×© ×¢×–×¨×”. ğŸ’™\n\n"
            else:
                response += "×ª×•×“×” ×¢×œ ×”×©×™×ª×•×£. ×× ×ª×¨×’×™×©×™ ×©××©×”×• ××©×ª× ×” ××• ×× ×ª×—×•×©×™ ×¦×•×¨×š, "
                response += "×ª××™×“ ××¤×©×¨ ×œ×©×•×‘ ×•×œ×©×•×—×— ××• ×œ×¤× ×•×ª ×œ×¢×–×¨×”. ğŸ’™\n\n"
            
            if self.ppd_agent is not None:
                response += f"ğŸ’¡ ×× ×ª×¨×¦×™, ×× ×™ ×™×›×•×œ×” ×œ×¢×–×•×¨ ×œ×”×¢×¨×™×š ××ª ×”××¦×‘ ×’× ×¢× ×›×œ×™ × ×•×¡×£. "
                response += f"×–×” ××•×¤×¦×™×•× ×œ×™ ×œ×—×œ×•×˜×™×Ÿ - ×¨×§ ×× ××ª ××¨×’×™×©×” ×‘× ×•×—."
            
            response += f"\nâœ… ×”×ª×©×•×‘×•×ª × ×©××¨×• ×‘×”×¦×œ×—×” (×¨×©×•××” #{record_id})"
            
            self.state.assessment_complete = True
        
        else:
            # Conversation completed or other state
            if self.state.assessment_complete:
                # Try to extract symptom info for XGBoost prediction
                if self.ppd_agent is not None and any(word in user_message.lower() for word in ['×›×Ÿ', '×¡××¤×˜×•××™×', '×ª×¡××™× ×™×', '×¡×™××¤×˜×•××™×']):
                    # User wants XGBoost prediction - would need to extract symptoms from conversation
                    response = "×× ×™ ×™×›×•×œ ×œ×¢×–×•×¨ ×¢× ×”×¢×¨×›×ª XGBoost. ×›×“×™ ×œ×§×‘×œ ×”×¢×¨×›×” ××“×•×™×§×ª, ×× ×™ ×¦×¨×™×š ××™×“×¢ ×¢×œ:\n"
                    response += "- ×’×™×œ\n- ×ª×—×•×©×•×ª ×©×œ ×¢×¦×‘\n- ×¢×¦×‘× ×•×ª ×›×œ×¤×™ ×”×ª×™× ×•×§/×‘×Ÿ ×”×–×•×’\n- ×‘×¢×™×•×ª ×©×™× ×”\n- ×§×©×™×™ ×¨×™×›×•×–\n- ×©×™× ×•×™×™× ×‘×ª×™××‘×•×Ÿ\n- ×—×¨×“×”\n- ×¨×’×©×•×ª ××©××”\n- ×§×©×™×™ ×§×©×¨ ×¢× ×”×ª×™× ×•×§\n- ××—×©×‘×•×ª ××•×‘×“× ×™×•×ª\n\n×× ×ª×¨×¦×™, ×× ×™ ×™×›×•×œ ×œ×¢×–×•×¨ ×œ××œ× ××ª ×”×©××œ×•×Ÿ ×”××œ×."
                else:
                    response = "×”×¢×¨×›×” ×”×•×©×œ××”. ×™×© ××©×”×• × ×•×¡×£ ×©×‘×¨×¦×•× ×š ×œ×“×•×Ÿ ×‘×•?"
            else:
                response = "×× × ×œ×—×¦×™ ×¢×œ '×”×ª×—×œ ×”×¢×¨×›×”' ×›×“×™ ×œ×”×ª×—×™×œ"
        
        # Add response to history
        self.state.conversation_history.append({
            "role": "assistant",
            "content": response
        })
        
        return response
    
    def _analyze_sentiment(self, text: str) -> Tuple[float, List[str]]:
        """Analyze sentiment and detect keywords."""
        try:
            sentiment = TextBlob(text).sentiment.polarity
            keywords = [k for k in DISTRESS_KEYWORDS if k in text]
            return sentiment, keywords
        except:
            return 0.0, []
    
    def _assess_risk(self, epds_score: int, sentiment: float, keywords: List[str]) -> Dict[str, str]:
        """Assess risk level based on EPDS score, sentiment, and keywords."""
        # EPDS risk levels
        if epds_score >= 13:
            risk_level = "×’×‘×•×”"
            recommendation = "××•××œ×¥ ×××•×“ ×œ×¤× ×•×ª ×œ×™×™×¢×•×¥ ××§×¦×•×¢×™ ×‘×”×§×“×"
        elif epds_score >= 10:
            risk_level = "×‘×™× ×•× ×™-×’×‘×•×”"
            recommendation = "××•××œ×¥ ×œ×¢×§×•×‘ ××—×¨×™ ×”××¦×‘ ×•×œ×©×§×•×œ ×™×™×¢×•×¥ ××§×¦×•×¢×™"
        else:
            risk_level = "× ××•×š-×‘×™× ×•× ×™"
            recommendation = "××•××œ×¥ ×œ×”××©×™×š ×œ×¢×§×•×‘ ××—×¨×™ ×”××¦×‘"
        
        # Adjust based on sentiment and keywords
        if sentiment < -0.3 or len(keywords) >= 2:
            if risk_level == "× ××•×š-×‘×™× ×•× ×™":
                risk_level = "×‘×™× ×•× ×™"
                recommendation = "××•××œ×¥ ×œ×©×§×•×œ ×©×™×—×” ×¢× ××™×© ××§×¦×•×¢"
        
        return {
            "risk_level": risk_level,
            "recommendation": recommendation
        }
    
    def reset(self):
        """Reset conversation state."""
        self.state = None

